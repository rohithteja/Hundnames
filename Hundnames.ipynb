{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hundnames.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ka9NpNixhhkkW0G6uz6sy6oZkbdFDmig","authorship_tag":"ABX9TyOdYBDsjFYEY9euQIFvnN69"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYL1Gfb2KKZf","executionInfo":{"status":"ok","timestamp":1624657143620,"user_tz":-120,"elapsed":535,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}},"outputId":"21511736-3051-49e9-bdfe-e432ffd813d1"},"source":["import pandas as pd\n","import numpy as np\n","import re\n","from bs4 import BeautifulSoup\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.util import flatten\n","nltk.download('stopwords')"],"execution_count":134,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"v1B345k7KLIP","executionInfo":{"status":"ok","timestamp":1624657694574,"user_tz":-120,"elapsed":187,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}}},"source":["#read data\n","df = pd.read_csv(\"20210103_hundenamen.csv\")"],"execution_count":154,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Jh5pCX72rd-G","executionInfo":{"status":"ok","timestamp":1624654656440,"user_tz":-120,"elapsed":205,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}},"outputId":"e8e7cf77-2187-4a92-9196-e6dff0ffdeb8"},"source":["df\n","\n","# since some names like \"Bo\" Bendy of Treegarden, has extra information other than the name,\n","# 2 cases are built, one with no preprocessing and one with preprocessing "],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HUNDENAME</th>\n","      <th>GEBURTSJAHR_HUND</th>\n","      <th>GESCHLECHT_HUND</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ituma</td>\n","      <td>2011</td>\n","      <td>w</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"Bo\" Bendy of Treegarden</td>\n","      <td>2020</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"Bobby\" Lord Sinclair</td>\n","      <td>2009</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"Buddy\" Fortheringhay's J.</td>\n","      <td>2011</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"Fly\" Showring i fly for you</td>\n","      <td>2015</td>\n","      <td>w</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8569</th>\n","      <td>unbekannt</td>\n","      <td>2010</td>\n","      <td>w</td>\n","    </tr>\n","    <tr>\n","      <th>8570</th>\n","      <td>unbekannt</td>\n","      <td>2011</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>8571</th>\n","      <td>unbekannt</td>\n","      <td>2018</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>8572</th>\n","      <td>unbekannt</td>\n","      <td>2018</td>\n","      <td>m</td>\n","    </tr>\n","    <tr>\n","      <th>8573</th>\n","      <td>unbekannt</td>\n","      <td>2017</td>\n","      <td>m</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8574 rows × 3 columns</p>\n","</div>"],"text/plain":["                         HUNDENAME  GEBURTSJAHR_HUND GESCHLECHT_HUND\n","0                            Ituma              2011               w\n","1         \"Bo\" Bendy of Treegarden              2020               m\n","2            \"Bobby\" Lord Sinclair              2009               m\n","3       \"Buddy\" Fortheringhay's J.              2011               m\n","4     \"Fly\" Showring i fly for you              2015               w\n","...                            ...               ...             ...\n","8569                     unbekannt              2010               w\n","8570                     unbekannt              2011               m\n","8571                     unbekannt              2018               m\n","8572                     unbekannt              2018               m\n","8573                     unbekannt              2017               m\n","\n","[8574 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4lIvkGsKLTz","executionInfo":{"status":"ok","timestamp":1624655545643,"user_tz":-120,"elapsed":8262,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}},"outputId":"ba2cdd53-8fd0-4c21-8c2f-27698d7fad6c"},"source":["# install python library\n","\n","pip install python-Levenshtein"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Collecting python-Levenshtein\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n","\r\u001b[K     |██████▌                         | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.0.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149808 sha256=d8747a0c5032902d7a24c8fce73146a6550c635509f0888e99182ae9f1c46404\n","  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein\n","Successfully installed python-Levenshtein-0.12.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2SH1B_fpKZmH"},"source":["# import \n","from Levenshtein import distance as levenshtein_distance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAtRw9G9EK2N","executionInfo":{"status":"ok","timestamp":1624656465957,"user_tz":-120,"elapsed":192,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}},"outputId":"0ee98e2c-a886-4de4-9aa8-116480c55ca4"},"source":["# CASE 1\n","# no preprocessing\n","\n","Levenshtein_distance = []\n","\n","for i in df.HUNDENAME.values:\n","  Levenshtein_distance.append(levenshtein_distance('luca',i))\n","\n","df['Levenshtein_distance'] = Levenshtein_distance\n","df[df.Levenshtein_distance==1].HUNDENAME.unique()\n","\n","# ['Cuca', 'Luca', 'Yuca'] are all names that have a Levenshtein distance of 1 to \"Luca\"\n","# we were able to find very less names with out preprocessing"],"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Cuca', 'Luca', 'Yuca'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qgvYwwtEK4i","executionInfo":{"status":"ok","timestamp":1624657931674,"user_tz":-120,"elapsed":3191,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ByILg-htuXhMIDK9-US5Z_24QJpZksJzfZX3=s64","userId":"01155222072916958278"}},"outputId":"79cf9642-e520-4c21-c202-13a9cd730c37"},"source":["# CASE 2\n","# splitting bigger names into small names and de-capitalizing all names\n","# in simple words, cleaning messy text\n","\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","\n","#Include: personal pronouns and possessive pronouns gender indicators\n","STOPWORDS = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n","    text = text.lower() # lowercase text\n","    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n","    return text\n","\n","\n","df['cleaned_Data'] = df['HUNDENAME'].apply(lambda x: clean_text(x))\n","temp = df.cleaned_Data.map(lambda x: x.split())\n","\n","# creating a new list of dog names from the dataset\n","dog_names = []\n","for i in temp.values:\n","  dog_names.append(i)\n","\n","dog_names_edited = list(set(flatten(dog_names))) # removes repetitions of names and outputs flattened list\n","\n","df_edit = pd.DataFrame(dog_names_edited,columns=[\"dognames\"]) # create new dataframe with names\n","\n","Levenshtein_distance = []\n","\n","for i in df_edit.dognames.values:\n","  Levenshtein_distance.append(levenshtein_distance('luca',i))\n","\n","df_edit['Levenshtein_distance'] = Levenshtein_distance\n","df_edit[df_edit.Levenshtein_distance==1].dognames.unique()\n","\n","# ['cuca', 'lula', 'luba', 'luna', 'lucy', 'yuca', 'lucas', 'luce',\n","#        'luka', 'luck', 'lua', 'lucia', 'lupa', 'luma']\n","\n","# total 14 names are found which is better than case 1\n","\n","# NOTE: all names are in lower cases "],"execution_count":160,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['cuca', 'lula', 'luba', 'luna', 'lucy', 'yuca', 'lucas', 'luce',\n","       'luka', 'luck', 'lua', 'lucia', 'lupa', 'luma'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":160}]},{"cell_type":"code","metadata":{"id":"yUZvlesEN1kD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhpXnb85KLWN"},"source":[""],"execution_count":null,"outputs":[]}]}